---
resampling_with:
    ed2_fname: 10-Chap-6
jupyter:
  jupytext:
    notebook_metadata_filter: all,-language_info
    split_at_heading: true
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.6
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{r setup, include=FALSE}
source("_common.R")
```

# Probability Theory, Part 2: Compound Probability {#sec-compound-probability}

:::{.callout-warning}
## Draft page partially ported from original PDF

This page is an automated and partial import from the [original second-edition
PDF](https://resample.com/content/text/10-Chap-6.pdf).

We are in the process of updating this page for formatting, and porting any
code from the original [RESAMPLING-STATS
language](http://www.statistics101.net) to Python and R.

Feel free to read this version for the sense, but expect there to be multiple
issues with formatting.

We will remove this warning when the page has adequate formatting, and we have
ported the code.
:::


<!---
We need if statement here.  Introduce here or before.
-->

<!---
Machinery for one pair, two pairs, three of a kind.

np.unique, return_count
-->



## Introduction

In this chapter we will deal with what are usually called "probability
problems" rather than the "statistical inference problems" discussed in
later chapters. The difference is that for probability problems we begin
with a knowledge of the properties of the universe with which we are
working. (See @sec-what-is-resampling on the definition of resampling.)

Before we get down to the business of complex probabilistic problems in
this and the next two chapters, let's consider a couple of peculiar
puzzles which do not fit naturally into any chapter in this book, but
which are extremely valuable in showing the power of the Monte Carlo
simulation method.

## Puzzle Problems

<!---
Are these a little too advanced?  Should we start with the poker problems?
-->

### The treasure fleet recovered

The problem is:

> A Spanish treasure fleet of three ships was sunk at sea off Mexico. One ship
> had a trunk of gold forward and another aft, another ship had a trunk of gold
> forward and a trunk of silver aft, while a third ship had a trunk of silver
> forward and another trunk of silver aft. Divers just found one of the ships
> and a trunk of gold in it. They are now taking bets about whether the other
> trunk found on the same ship will contain silver or gold. What are fair odds?

(This is a restatement of [a problem that Joseph Bertrand
posed](https://en.wikipedia.org/wiki/Bertrand%27s_box_paradox) early in the
19th century.)  Here is a variation from [@goldberg1986probability, page 99]:

> Three identical boxes each contain two coins. In one box both are pennies, in
> the second both are nickels, and in the third there is one penny and one
> nickel.
>
> A man chooses a box at random and takes out a coin. If the coin is a penny,
> what is the probability that the other coin in the box is also a penny?

These are the logical steps one may distinguish in arriving at a correct
answer with deductive logic (portrayed in @fig-ships-gold-silver).

1.  Postulate three ships — Ship I with two gold chests (G-G), ship II
    with one gold and one silver chest (G-S), and ship III with S-S.
    (Choosing notation might well be considered one or more additional
    steps.)
2.  Assert equal probabilities of each ship being found.
3.  Step 2 implies equal probabilities of being found for each of the
    six chests.
4.  Fact: Diver finds a chest of gold.
5.  Step 4 implies that S-S ship III was not found; hence remove it from
    subsequent analysis.
6.  Three possibilities: 6a) Diver found chest I-Ga, 6b) diver found
    I-Gb, 6c) diver found II-Gc.

    From step 2, the cases a, b, and c in step 6 have equal
    probabilities.
7.  If possibility 6a is the case, then the other trunk is I-Gb; the
    comparable statements for cases 6b and 6c are I-Ga and II-S.
8.  From steps 6 and 7: From equal probabilities of the three cases, and
    no other possible outcome, $P(6a) = 1/3$, $P(6b) = 1/3$, $P(6c) =
    1/3$.
9.  So $P(G) = P(6a) + P(6b)$ = 1/3 + 1/3 = 2/3.

See @fig-ships-gold-silver.

```{r fig-ships-gold-silver, echo=FALSE, fig.align="center", fig.cap="Ships with Gold and Silver"}
include_svg('images/ships_gold_silver.svg')
```

The following simulation arrives at the correct answer:

1.  Write "Gold" on three pieces of paper and "Silver" on three pieces of
    paper.
2.  Get three buckets each with two pieces of paper:  one with "Gold", "Gold",
    one with "Gold", "Silver", and one with "Silver", "Silver".
3.  Choose a bucket at random, and shuffle the pieces of paper in it.
4.  Choose the first element in the chosen bucket's vector (a vector is an
    array or list of things). If "Silver", stop trial and make no further
    record. If "Gold", continue.
5.  Record the second element in the chosen bucket's vector on the
    scoreboard.
6.  Repeat steps (3 - 5), and calculate the proportion of "Gold"'s on a
    scoreboard. (The answer should be about $\frac{2}{3}$.)

Here is a notebook simulation with {{< var lang >}}:

<!---
We need strings at this point.
-->

::: {.notebook name="gold_silver_ships" title="Ships with gold and silver"}

::: nb-only
In which we solve the problem of gold and silver chests in a discovered ship.
:::

```{python opts.label="py_ed"}
import numpy as np
rnd = np.random.default_rng()
```

```{python opts.label="py_ed"}
# The 3 buckets, each representing two trunks on a ship.
bucket1 = ['Gold', 'Gold']  # First ship.
bucket2 = ['Gold',  'Silver']  # Second ship.
bucket3 = ['Silver', 'Silver']  # Third ship.
```

```{python opts.label="py_ed"}
# Mark trials as not valid to start with.
# Trials where we don't get a gold trunk first will
# keep this 'No gold in first trunk' marker.
second_trunks = np.repeat(['No gold in first trunk'], 10000)

for i in range(10000):
    # Select a ship at random from the three ships.
    ship_no = rnd.choice([1, 2, 3])
    # Get the trunks from this ship.
    if ship_no == 1:
        bucket = bucket1
    elif ship_no == 2:
        bucket = bucket2
    else:  # ship_no == 3
        bucket = bucket3

    shuffled = rnd.permuted(bucket)

    if shuffled[0] == 'Gold':  # We found a gold trunk first.
        # Store whether the Second trunk was silver or gold.
        second_trunks[i] = shuffled[1]

# End loop, go back to beginning.

# Number of times we found gold in the second trunk.
n_golds = np.sum(second_trunks == 'Gold')
# Number of times we found silver in the second trunk.
n_silvers = np.sum(second_trunks == 'Silver')
# As a ratio of golds to all second trunks (where the first was gold).
print(n_golds / (n_golds + n_silvers))
```

```{r opts.label="r_ed"}
# The 3 buckets, each representing two trunks on a ship.
bucket1 <- c('Gold', 'Gold')  # First ship.
bucket2 <- c('Gold',  'Silver')  # Second ship.
bucket3 <- c('Silver', 'Silver')  # Third ship.
```

```{r opts.label="r_ed"}
# Mark trials as not valid to start with.
# Trials where we don't get a gold trunk first will
# keep this 'No gold in first trunk' marker.
second_trunks = rep('No gold in first trunk', 10000)

for (i in 1:10000) {
    # Select a ship at random from the three ships.
    ship_no <- sample(1:3, size=1)
    # Get the trunks from this ship.
    if (ship_no == 1) {
        bucket <- bucket1
    } else if (ship_no == 2) {
        bucket <- bucket2
    } else {  # ship_no == 3
        bucket <- bucket3
    }

    shuffled <- sample(bucket)

    if (shuffled[1] == 'Gold') {  # We found a gold trunk first.
        # Store whether the Second trunk was silver or gold.
        second_trunks[i] <- shuffled[2]
    }
}  # End loop, go back to beginning.

# Number of times we found gold in the second trunk.
n_golds <- sum(second_trunks == 'Gold')
# Number of times we found silver in the second trunk.
n_silvers <- sum(second_trunks == 'Silver')
# As a ratio of golds to all second trunks (where the first was gold).
message(n_golds / (n_golds + n_silvers))
```

:::


### The Monty Hall problem

The Monty Hall Problem is a puzzle in probability that is famous for its
deceptive simplicity.  It has its own long Wikipedia page:
<https://en.wikipedia.org/wiki/Monty_Hall_problem>.

Here is the problem in its most famous form; a letter to the columnist
[Marilyn vos Savant](https://en.wikipedia.org/wiki/Marilyn_vos_Savant),
published in Parade Magazine [-@savant1990monty]:

> Suppose you’re on a game show, and you’re given the choice of three doors.
> Behind one door is a car, behind the others, goats. You pick a door, say #1,
> and the host, who knows what’s behind the doors, opens another door, say #3,
> which has a goat. He says to you, "Do you want to pick door #2?" Is it to
> your advantage to switch your choice of doors?

In fact the first person to propose (and solve) this problem was Steve Selvin,
a professor of public health at the University of California, Berkeley
[@slevin1975monty].

Most people, including at least one of us, your humble authors, quickly come to
the wrong conclusion.  The most common but incorrect answer is that it will
make no difference if you switch doors or stay with your original choice.  The
obvious intuition is that, after Monty opens his door, there are two doors that
might have the car behind them, and therefore, there is a 50% chance it will be
behind any one of the two. It turns out that answer is wrong; you will double
your chances of winning by switching doors. Did you get the answer right?

If you got the answer wrong, you are in excellent company.  As you can see
from the commentary in @savant1990monty, many mathematicians wrote to Parade
magazine to assert that the (correct) solution was wrong.  [Paul
Erdős](https://en.wikipedia.org/wiki/Paul_Erd%C5%91s) was one of the most
famous mathematicians of the 20th century; he could not be convinced of the
correct solution until he had seen a computer simulation [@vazsonyi1999door],
of the type we will do below.

To simulate a trial of this problem, we need to select a door at random to
house the car, and another door at random, to be the door the contestant
chooses.  We number the doors 1, 2 and 3.   Now we need two random choices
from the options 1, 2 or 3, one for the door with the car, the other for the
contestant door.  To chose a door for the car, we could throw a die, and chose
door 1 if the die shows 1 or 4, door 2 if the die shows 2 or 5, and door 3 for
3 or 6.  Then we throw the die again to chose the contestant door.

But throwing dice is a little boring; we have to find the die, then throw it
many times, and record the results.   Instead we can ask the computer to chose
the doors at random.

```{r echo=FALSE}
n_trials <- 25
```

For this simulation, let us do `r n_trials` trials.  We ask the computer to
create two sets of `r n_trials` random numbers from 1 through 3. The first set
is the door with the car behind it ("Car door").  The second set have the door
that the contestant chose at random ("Our door").   We put these in a table,
and make some new, empty columns to fill in later.  The first new column is
"Monty opens".  In due course, we will use this column to record the door that
Monty Hall will open on this trial.  The last two columns express the outcome.
The first is "Stay wins".  This has "Yes" if we win on this trial by sticking
to our original choice of door, and "No" otherwise.  The last column is
"Switch wins". This has "Yes" if we win by switching doors, and "No"
otherwise. See table @tbl-montyblank).

```{python echo=FALSE}
# Need Python for random numbers that are predictable across platforms.
import numpy as np
import pandas as pd

# Seed chosen such that it generates [3, 3] then [3, 1]
monty_rng = np.random.default_rng(2037)
n_trials = int(r.n_trials)
random_matrix = monty_rng.integers(1, 4, size=(n_trials, 2))
# We need these rows for the example.
assert np.all(random_matrix[:2] == [[3, 3], [3, 1]])
df = pd.DataFrame(random_matrix)
df.columns = ('Car door', 'Our door')
# Set the columns to fill in later.
# It would be more efficient to use `df.assign` here, but less readable.
df['Monty opens'] = ''
df['Stay wins'] = ''
df['Switch wins'] = ''
```

```{r montyblank, echo=FALSE}
blank_df <- tibble::as_tibble(py$df)
knitr::kable(blank_df,
  booktabs = TRUE,
  row.names = TRUE,
  caption = sprintf('%d simulations of the Monty Hall problem
                    {#tbl-montyblank}', n_trials)
)
```

```{r echo=FALSE}
# Do the calculation
fdf <- blank_df
# Convert Monty opens column to integer, for car door number.
fdf['Monty opens'] <- as.integer(NA)
# Cycle over each row in the original data frame.
for (i in 1:dim(fdf)[1]) {
    car_door <- fdf[i, 'Car door']
    our_door <- fdf[i, 'Our door']
    # Remove our door from consideration.  There are two doors remaining.
    remaining_doors <- setdiff(1:3, our_door)
    if (our_door == car_door) {   # Our door does match car door.
        fdf[i, 'Stay wins'] <- 'Yes'
        fdf[i, 'Switch wins'] <- 'No'
        # Choose one of the remaining (goat) doors at random.
        fdf[i, 'Monty opens'] <- sample(remaining_doors, 1)
    } else {  # our door did not match.
        fdf[i, 'Stay wins'] <- 'No'
        # Monty must open the remaining door that isn't the car door.
        fdf[i, 'Monty opens'] <- setdiff(remaining_doors, car_door)
        # The only one left is the car door.
        fdf[i, 'Switch wins'] <- 'Yes'
    }
}
```

In the first trial in @tbl-montyblank), the computer selected door 3 for
car, and door 3 for the contestant.  Now Monty must open a door, and he cannot
open our door (door 3) so he has the choice of opening door 1 or door 2; he
chooses randomly, and opens door 2.  On this trial, we win if we stay with our
original choice, and we lose if we change to the remaining door, door 1.

Now we go the second trial.  The computer chose door 3 for the car, and door 1 for our choice.  Monty cannot choose our door (door 1) or the door with the car behind it (door 3), so he must open door 2.   Now if we stay with our original choice, we lose, but if we switch, we win.

You may want to print out table @tbl-montyblank, and fill out the blank
columns, to work through the logic.

After doing a few more trials, and some reflection, you may see that there are
two different situations here: the situation when our *initial guess was
right*, and the situation where our *initial guess was wrong*.   When our
initial guess was right, we win by staying with our original choice, but when
it was wrong, we always win by switching.   The chance of our *initial guess*
being correct is 1/3 (one door out of three).  So the chances of winning by
staying are 1/3, and the chances of winning by switching are 2/3.  But
remember, you don't need to follow this logic to get the right answer.  As you
will see below, the resampling simulation shows us that the Switch strategy
wins.

Table @tbl-montyfull is a version of table @tbl-montyblank for
which we have filled in the blank columns using the logic above.

```{r montyfull, echo=FALSE}
knitr::kable(fdf,
  booktabs = TRUE,
  row.names = TRUE,
  caption = sprintf('%d simulations of the Monty Hall problem, filled out
  {#tbl-montyfull}', n_trials)
)
```

The proportion of times "Stay" wins in these `r n_trials` trials is
`r sum(fdf['Stay wins'] == 'Yes') / n_trials`.
The proportion of times "Switch" wins is
`r sum(fdf['Switch wins'] == 'Yes') / n_trials`; the Switch strategy wins about twice as often as the Stay strategy.

We won't elaborate the full {{< var lang >}} simulation here, but you might
want to think about how you would do that.

Doing these simulations has two large benefits.   First, it gives us the right answer, saving us from making a mistake.  Second, the process of simulation forces us to think about how the problem works.  This can give us better understanding, and make it easier to reason about the solution.

We will soon see that these same advantages also apply to reasoning about
statistics.

## Examples of basic problems in probability

### A Poker Problem: One Pair (Two of a Kind) {#sec-one-pair}

What is the chance that the first five cards chosen from a deck of 52
(bridge/poker) cards will contain two (and only two) cards of the same
denomination (two 3's for example)? (Please forgive the rather sterile
unrealistic problems in this and the other chapters on probability. They
reflect the literature in the field for 300 years. We'll get more
realistic in the statistics chapters.)

We shall estimate the odds the way that gamblers have estimated gambling
odds for thousands of years. First, check that the deck is a
standard deck and is not missing any cards. (Overlooking such small but crucial
matters often leads to errors in science.) Shuffle thoroughly until you are
satisfied that the cards are randomly distributed. (It is surprisingly hard to
shuffle well.) Then deal five cards, and mark down whether the hand does or
does not contain a pair of the same denomination.

At this point, we must decide whether three of a kind, four of a kind or two
pairs meet our criterion for a pair. Since our criterion is "two and only two,"
we decide *not* to count them.

Then replace the five cards in the deck, shuffle, and deal again. Again
mark down whether the hand contains one pair of the same denomination.
Do this many times. Then count the number of hands with one pair, and
figure the proportion (as a percentage) of all hands.

```{python, echo=FALSE}
n_deals = 25
```

@tbl-one-pair has the results of `r py$n_deals` hands of this procedure.

```{python, echo=FALSE}
from itertools import product
suit_chars = ['\N{Black Spade Suit}',
    '\N{White Heart Suit}',
    '\N{White Diamond Suit}',
    '\N{Black Club Suit}']
denom = ['Ace'] + [str(s) for s in range(2, 11)] + ['Jack', 'Queen', 'King']
values = list(range(1, 14)) * 4
deck = [f'{d} {s}' for s, d in product(suit_chars, denom)]
deck_values = dict(zip(deck, values))
```

```{python, results='asis', echo=FALSE, message=FALSE}
import numpy as np
import pandas as pd
seed = 1937
rnd = np.random.default_rng(seed)
df = pd.DataFrame(columns=['Card 1',
                           'Card 2',
                           'Card 3',
                           'Card 4',
                           'Card 5',
                           'One pair?'],
                  index=pd.Index(range(1, n_deals + 1), name='Hand'))
for i in range(1, n_deals + 1):
    cards = rnd.choice(deck, size=5, replace=False)
    df.loc[i, 'Card 1':'Card 5'] = cards
    values = [deck_values[c] for c in cards]
    counts = np.bincount(values)
    df.loc[i, 'One pair?'] = 'Yes' if np.sum(counts == 2) == 1 else 'No'

pct = int(np.round(np.sum(df['One pair?'] == 'Yes') / len(df) * 100))
n_cols = len(df.columns)
df.loc['', :] = [''] * n_cols
df.loc['**% Yes**', :] = [''] * (n_cols - 1) + [f'{pct}%']

cards_tab = df.to_markdown(tablefmt="grid")
print(f'{cards_tab}\n\n: Results of {n_deals} hands '
      'for the problem "one pair" {#tbl-one-pair}')
```

In this series of `r py$n_deals` experiments, `r py$pct` percent of the hands
contained one pair, and therefore `r py$pct / 100` is our estimate (for the
time being) of the probability that one pair will turn up in a poker hand. But
we must notice that this estimate is based on only `r py$n_deals` hands, and
therefore might well be fairly far off the mark (as we shall soon see).

This experimental "resampling" estimation does not require a deck of cards. For
example, one might create a 52-sided die, one side for each card in the deck,
and roll it five times to get a "hand." But note one important part of the
procedure: No single "card" is allowed to come up twice in the same set of five
spins, just as no single card can turn up twice or more in the same hand. If
the same "card" did turn up twice or more in a dice experiment, one could
pretend that the roll had never taken place; this procedure is necessary to
make the dice experiment analogous to the actual card-dealing situation under
investigation. Otherwise, the results will be slightly in error. This type of
sampling is known as "sampling without replacement," because each card is *not
replaced* in the deck prior to dealing the next card (that is, prior to the end
of the hand).

Still another resampling method uses a *random number table* , such as
that which is shown in @tbl-random-digits. Arbitrarily designate the spades as
numbers "01-13," the diamonds as "14-26," the hearts as "27-39," and the clubs
as "40-52." Then proceed across a row (or down a column), writing down each
successive pair of digits, excluding pairs outside "01-52" and omitting
duplication within sets of five numbers. Then translate them back into cards,
and see how many "hands" of five "cards" contain one pair each. Table 6-4 shows
six such hands, of which hands numbered 2, 3 and 6 contain pairs.




---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
48   52   78   38   11   90   41   83   43   99   51   55   57   03   83   20
15   11   84   33   09   24   08   52   42   70   37   16   66   73   15   54
25   89   70   11   91   65   41   90   88   04   30   72   15   81   34   46
34   24   66   55   67   79   29   18   36   56   96   95   35   06   05   10
37   27   58   38   23   84   94   39   99   50   74   80   41   85   98   63
12   17   04   68   19   98   53   44   16   32   91   01   71   60   19   12
88   85   44   65   52   01   99   56   72   07   96   39   56   34   86   01
81   92   77   83   10   58   92   33   63   48   62   66   32   61   59   74
08   50   15   18   13   45   65   12   32   92   53   82   07   61   71   80
84   29   90   36   05   95   20   71   17   82   83   38   01   87   74   92
77   76   46   28   47   15   04   21   04   75   51   83   91   37   14   32
01   33   90   94   86   10   03   99   95   98   76   97   97   26   45   62
---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----

: Table of Random Digits {#tbl-random-digits}



Aces 2 3 4 5 6 7 8 9 10 J Q K


  ------------------------ ---- ---- ---- ---- ---- ---------- ---- ---- ---- ---- ---- ---- ----
  Spades                   01   02   03   04   05   06         07   08   09   10   11   12   13
  Diamonds                 14   15   16   17   18   19         20   21   22   23   24   25   26
  Hear ts                  27   28   29   30   31   32         33   34   35   36   37   38   39
  Clubs                    40   41   42   43   44   45         46   47   48   49   50   51   52


: What the Random Numbers Mean {#tbl-numbers-to-cards}

  **Simulation Results**                                                                     
  Hand 1:                  48   52   38   11   41   no pairs                                 
  Hand 2:                  15   11   33   09   24   one pair                                 
  Hand 3:                  25   11   41   04   30   one pair                                 
  Hand 4:                  34   24   29   18   36   no pairs                                 
  Hand 5:                  37   27   38   23   39   no pairs                                 
  Hand 6:                  12   17   04   19   44   one pair                                 
  ------------------------ ---- ---- ---- ---- ---- ---------- ---- ---- ---- ---- ---- ---- ----

:Six Simulated Trials for the Problem "OnePair {#tbl-six-one-pair-sims}

Now let's do the same job using RESAMPLING STATS on the computer. Let's
name "One Pair" the file which simulates a deck of playing cards and
solves the problem.

Our first task is to simulate a deck of playing cards analogous to the
real cards we used previously. We don't need to simulate all the
features of a deck, but only the features that matter for the problem at
hand. We require a deck with four "1"s, four "2"s, etc., up to four
"13"s. The suits don't matter for our present purposes. Therefore, with
the URN command we join together in a single array the four sets of
thirteen numbers, to represent the 13 denominations.

At this point we have a complete deck in location A. But that "deck" is
in the same order as a new deck of cards. If we do not shuffle the deck,
the results will be predictable. Therefore, we write SHUFFLE a b and
then deal a poker hand by taking the first five cards from the shuffled
hand, using the TAKE statement. Now we must find out if there is one
(and only one) pair; we do this with the MULTIPLES statement — the "2"
in that statement indicates that it is a duplicate, rather than a
singleton or triplicate or quadruplicate that we are testing for — and
we put the result in location D. Next we SCORE in location z how many
pairs there are, the number in each trial being either zero, one, or
two. (The reason we cannot put the result of the MULTIPLES operation
directly into the scorecard vector z is that only the SCORE command
accumulates results from trial to trial rather than over-writing the
result of the past trial with the current one.) And with that we end a
single trial.

With the REPEAT 10000 statement and the END statement, we command the
program to do ten thousand repeats of the statements in the "loop" between
those two lines.

When those 10000 repetitions are over, the computer moves on to
COUNT the number of "1's" in SCOREkeeping vector z, each "1" indicating a hand
with a pair. And we then PRINT to the screen the result which is found in
location k. If we want the *proportion* of the trials in which a pair occurs,
we simply divide the results of the thousand trials by 10000.

<!---
Introduce bincount / tabulate / repeat
-->

::: {.notebook name="one_pair" title="One pair"}

::: nb-only
This is a simulation to find the probability of exactly one pair in a poker
hand of five cards.
:::

```{python opts.label="py_ed"}
import numpy as np
rnd = np.random.default_rng()
```

```{python opts.label="py_ed"}
# Create a bucket (vector) called a with four "1's," four "2's," four "3's,"
# etc., to represent a deck of cards
one_suit = np.arange(1, 14)
one_suit
```

```{python opts.label="py_ed"}
# Repeat values for one suit four times to make a 52 card deck of values.
deck = np.repeat(one_suit, 4)
deck
```

```{python opts.label="py_ed"}
# Array to store result of each trial.
z = np.zeros(10000)

# Repeat the following steps 10000 times
for i in range(10000):
    # Shuffle the deck
    shuffled = rnd.permuted(deck)

    # Take the first five cards to make a hand.
    hand = deck[:5]

    # How many pairs?
    # Counts for each card rank.
    counts = np.bincount(hand)
    n_pairs = np.sum(counts == 2)

    # Keep score of # of pairs
    z[i] = n_pairs

    # End loop, go back and repeat

# How often was there 1 pair?
k = np.sum(z == 1)

# Convert to proportion.
kk = k / 10000

# Show the result.
print(kk)
```

```{r opts.label="r_ed"}
# Create a bucket (vector) called a with four "1's," four "2's," four "3's,"
# etc., to represent a deck of cards
one_suit = 1:13
one_suit
```

```{r opts.label="r_ed"}
# Repeat values for one suit four times to make a 52 card deck of values.
deck = rep(one_suit, 4)
deck
```

```{r opts.label="r_ed"}
# Vector to store result of each trial.
z <- numeric(10000)

# Repeat the following steps 10000 times
for (i in 1:10000) {
    # Shuffle the deck
    shuffled <- sample(deck)

    # Take the first five cards to make a hand.
    hand = shufffled[1:5]

    # How many pairs?
    # Counts for each card rank.
    counts <- tabulate(hand)
    n_pairs <- sum(counts == 2)

    # Keep score of # of pairs
    z[i] <- n_pairs

    # End loop, go back and repeat
}

# How often was there 1 pair?
k <- sum(z == 1)

# Convert to proportion.
kk = k / 10000

# Show the result.
message(kk)
```

:::

```{r, echo=FALSE}
rkk <- round(get_var('kk'), 3)
```

In one run of the program, the result in `kk` was `r rkk`, so our estimate
would be that the probability of a single pair is `r rkk`.

How accurate are these resampling estimates? The accuracy depends on the
*number of hands* we deal — the more hands, the greater the accuracy. If
we were to examine millions of hands, 42 percent would contain a pair
each; that is, the chance of getting a pair in the long run is 42
percent. It turns out the estimate of `r py$pct` percent based on 
`r py$n_deals` hands in @tbl-one-pair is fairly close to the long-run
estimate, though whether or not it is close *enough* depends on one's needs of
course. If you need great accuracy, deal many more hands.

A note on the `a`s, `b`s, `c`s in the above program, etc.: These "variables"
are called "{{< var array >}}"s in {{< var lang >}}. A *{{< var array >}}* is
an array (sequence) of elements that gets filled with numbers as {{< var lang
>}} conducts its operations. When {{< var lang >}} completes a single trial
these {{< var array >}}s are generally reset except for the "score" {{< var
array >}} (here labeled `z`) which keeps track of the result of each trial.

To help keep things straight (though the program does not require it), we
usually use `z` to name the {{< var array >}} that collects all the trial
results, and `k` to denote our overall summary results. Or you could call it
something like `scoreboard` — it's up to you.

How many trials (hands) should be made for the estimate? There is no
easy answer.[^how-many-trials] One useful device is to run several (perhaps
ten) equal sized sets of trials, and then examine whether the proportion of
pairs found in the entire group of trials is very different from the
proportions found in the various subgroup sets. If the proportions of pairs in
the various subgroups differ greatly from one another or from the overall
proportion, then keep running additional larger subgroups of trials until the
variation from one subgroup to another is sufficiently small for your purposes.
While such a procedure would be impractical using a deck of cards or any other
physical means, it requires little effort with the computer and {{< var lang
>}}.

[^how-many-trials]: One simple rule-of-thumb is to quadruple the original
    number. The reason for quadrupling is that four times as many iterations
    (trials) of this resampling procedure give *twice* as much accuracy (as
    measured by the standard deviation, the most frequent measurement of
    accuracy). That is, the error decreases with the square root of the number
    of iterations. If you see that you need *much* more accuracy, then
    *immediately* increase the number of iterations even more than four times
    — perhaps ten or a hundred times.

### Another Introductory Poker Problem

Which is more likely, a poker hand with two pairs, or a hand with three
of a kind? This is a *comparison* problem, rather than a problem in
*absolute* estimation as was the previous example.

In a series of 100 "hands" that were "dealt" using random numbers, four
hands contained two pairs, and two hands contained three of a kind. Is
it safe to say, on the basis of these 100 hands, that hands with two
pairs are more frequent than hands with three of a kind? To check, we
deal another 300 hands. Among them we see fifteen hands with two pairs
(3.75 percent) and eight hands with three of a kind (2 percent), for a
total of nineteen to ten. Although the difference is not enormous, it is
reasonably clear-cut. Another 400 hands might be advisable, but we shall
not bother.

Earlier I obtained forty-four hands with *one* pair each out of 100
hands, which makes it quite plain that *one* pair is more frequent than
*either* two pairs or three-of-a-kind. Obviously, we need *more* hands
to compare the odds in favor of two pairs with the odds in favor of
three-of-a-kind than to compare those for one pair with those for either
two pairs or three-of-a-kind. Why? Because the difference in odds
between one pair, and either two pairs or three-of-a-kind, is much
greater than the difference in odds between two pairs and
three-of-a-kind. This observation leads to a general rule: The closer
the odds between two events, the *more trials* are needed to determine
which has the higher odds.

Again it is interesting to compare the odds with the formulaic
mathematical computations, which are 1 in 21 (4.75 percent) for a hand
containing two pairs and 1 in 47 (2.1 percent) for a hand containing
three-of-a-kind — not too far from the estimates of .0375 and .02
derived from simulation.

To handle the problem with the aid of the computer, we simply need to
estimate the proportion of hands having triplicates and the proportion
of hands with two pairs, and compare those estimates.

To estimate the hands with three-of-a-kind, we can use a program just
like "One Pair" earlier, except instructing the MUL- TIPLES statement to
search for triplicates instead of duplicates. The program, then, is:

```{python opts.label="py_ed"}
triples_per_trial = np.zeros(10000)

# Repeat the following steps 10000 times
for i in range(10000):
    # Shuffle the deck
    np.random.shuffle(deck)

    # Take the first five cards.
    hand = deck[:5]

    # How many triples?
    counts = np.bincount(hand)
    n_triples = np.sum(counts == 3)

    # Keep score of # of triples
    triples_per_trial[i] = n_triples

    # End loop, go back and repeat

# How often was there 1 pair?
n_triples = np.sum(triples_per_trial == 1)

# Convert to proportion
print(n_triples / 10000)
```

Note: The file "3kind" on the Resampling Stats software disk contains
this set of commands.

To estimate the probability of getting a two-pair hand, we revert to the
original program (counting pairs), except that we examine all the
results in SCOREkeeping vector z for hands in which we had *two* pairs,
instead of *one* .

```{python opts.label="py_ed"}
pairs_per_trial = np.zeros(10000)

# Repeat the following steps 10000 times
for i in range(10000):
    # Shuffle the deck
    np.random.shuffle(deck)

    # Take the first five cards.
    hand = deck[:5]

    # How many pairs?
    # Counts for each card rank.
    counts = np.bincount(hand)
    n_pairs = np.sum(counts == 2)

    # Keep score of # of pairs
    pairs_per_trial[i] = n_pairs

    # End loop, go back and repeat

# How often were there 2 pairs?
n_two_pairs = np.sum(pairs_per_trial == 2)

# Convert to proportion
print(n_two_pairs / 10000)
```

Note: The file "2pair" on the Resampling Stats software disk contains
this set of commands.

For efficiency (though efficiency really is not important here because
the computer performs its operations so cheaply) we could develop both
estimates in a single program by simply generating 10000 hands, and count
the number with three-of-a-kind and the number with two pairs.

Before we leave the poker problems, we note a difficulty with Monte
Carlo simulation. The probability of a royal flush is so low (about one
in half a million) that it would take much computer time to compute. On
the other hand, considerable inaccuracy is of little matter. Should one
care whether the probability of a royal flush is 1/100,000 or 1/500,000?

## The concepts of replacement and non-replacement

In the poker example above, we *did not replace* the first card we drew.
If we were to replace the card, it would leave the probability the same
before the second pick as before the first pick. That is, the
conditional probability remains the same. *If we replace, conditions do
not change.* But if we do not replace the item drawn, the probability
changes from one moment to the next. (Perhaps refresh your mind with the
examples in the discussion of conditional probability including
@sec-example-four-events)

If we sample with replacement, the sample drawings remain *independent* of each
other — a topic addressed in @sec-independence.

In many cases, a key decision in modeling the situation in which we are
interested is whether to sample with or without replacement. The choice
must depend on the characteristics of the situation.

There is a close connection between the lack of finiteness of the
concept of universe in a given situation, and sampling with replacement.
That is, when the universe (population) we have in mind is not small, or
has no conceptual bounds at all, then the probability of each successive
observation remains the same, and this is modeled by sampling with
replacement. ("Not finite" is a less expansive term than "infinite,"
though one might regard them as synonymous.)

@sec-infinite-universes discusses problems whose appropriate concept of a universe is
finite, whereas @sec-finite-universes discusses problems whose appropriate concept
of a universe is not finite. This general procedure will be discussed
several times, with examples included.
