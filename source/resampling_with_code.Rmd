---
jupyter:
  jupytext:
    metadata_filter:
      notebook:
        additional: all
        excluded:
        - language_info
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 0.8.6
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
resampling_with:
    ed2_fname: null
---

```{r setup, include=FALSE}
source("_common.R")
```

# Resampling with code

Chapter @sec-resampling-method used simulation and resampling from
tables of random numbers, dice, and coins.  Making random choices in this way
can make it easier to understand the process, but of course, physical methods
of making random outcomes can be slow and boring.

We saw that short computer programs can do a huge number of resampling
trials in a few seconds.  The flexibility of a programming language makes it
possible to simulate many different outcomes and tests.

Programs can build up tables of random numbers, and do simple
tasks like counting the number of values in a row or taking
proportions.  With these simple tools, we can simulate many problems
in probability and statistics.

In this chapter, we will again model a problem using
{{< var lang >}},
but this time we will explain how the code works in more detail.

By the end of the chapter, you will be able to understand better how
{{< var lang >}}
can build up complete simulations using random numbers, and how the programming instructions relate to the tasks we need to do.

We have already emphasized that *statistics* is a way of drawing conclusions
about data from the real world, in the presence of random variation, and
*probability* is the way of reasoning about random variation.  This chapter
introduces our first *statistical* problem, where we use probability to draw
conclusions about some important data — about a potential cure for a type of
cancer.  We will not make much of the distinction between probability and
statistics here, but we will come back to it several times in later chapters.

<!---
*TODO* - Check we have discussed this before.
-->

## A new treatment for Burkitt lymphoma

[Burkitt lymphoma](https://en.wikipedia.org/wiki/Burkitt_lymphoma) is a rather
unusual cancer of the lymphatic system.  The lymphatic system is a vein-like
network throughout the body that is involved in the immune reaction to
disease. In developed countries, with standard treatment, the cure rate for
Burkitt lymphoma is about 90%.

In 2006, researchers in the US National Cancer Institute tested a new
treatment for Burkitt lymphoma. They gave their new treatment to 17 patients,
and found that all 17 patients were "cured" — meaning that the disease had not
progressed in any of the 17 patients, in more than two years of follow-up.

Here is where we put on our statistical hat and wonder
whether the 100% could be due to random variation.

How could it happen, by chance, that 17 out of 17 patients were cured?

We know that the average cure rate in the developed world is 90%.  Lacking any further information, we could therefore think of each patient being treated as having a 90% chance of being cured.  If a patient now receives the new treatment and is cured, does this tell us whether the new treatment is better than the standard treatment? We don't really know: as long as the new treatment isn't significantly worse than the standard treatment, curing the patient is the expected outcome.

What if we treat two patients with the new treatment, and they are both cured?
We are still not sure the new treatment is better, because, even if the
treatment is exactly as effective as the standard treatment, both patients
individually had a very good chance of cure, so it seems likely that there's a
pretty good chance they would both be cured.  Still, if both patients are
cured, that still seems like better evidence than just one patient being
cured.

Now we get to the question at hand.  The National Cancer Institute study found
the new treatment cured 17 out of 17 patients.  If the new treatment is
exactly as effective as the standard treatments, at 90% rate of cure, then we
would expect a lot of the patients to be cured.  But, if it is really true
that each patient has a 90% chance of cure, how likely is it that all 17
patients would be cured?  It seems like something that could happen, but how
likely is it? In other words, is the result that the researchers saw something
special that warrants further investigation, or is it something that could reasonably have come about by chance?

This is exactly the kind of question we ask in statistics — is this result
*surprising* or *unusual*, given that we know that there is an element of
chance?

First we come up with a *model* of the world we expect, when the treatment is
90% effective.  This model has to allow for *chance* because each patient has
a 90% *chance* of cure.

It is often useful to think how we would make a physical model of chance in
this world.  For example, to simulate whether a given patient is cured or not
by a 90% effective treatment, we could throw a ten sided die and record the
result.  We could say, arbitrarily, that a result of 0 means "not cured", and
all the numbers 1 through 9 mean "cured" (typical 10-sided dice have sides
numbered 0 through 9).

We could roll 17 dice to simulate one "trial" in this random world.  For each
trial, we record the number of dice that show numbers 1 through 9 (and not
0).  This will be a number between 0 and 17, and it is the number of patients
"cured" in our simulated trial.

Here is the result of one such trial we did with a set of 17 10-sided dice we happened to have near to hand:

:::{.callout-note}
We need a photo of 17 10-sided dice here
:::

In this case there is one 0, and the rest are from 1 through 9, so there were 16 out of 17 "patients" who were "cured" in this trial.

<!---
Adapt above to picture.
-->

We can use the computer to do something very similar.   We can ask the
computer for 17 random counting numbers from 0 through 9.

:::{.callout-note}
## Counting numbers

A counting number is a number that you use for counting things, and are also
called *whole* numbers or *integers*.  0 and 1 and 2 and 3 are counting
numbers, but 1.5 is not.  The counting numbers from 0 through 9 are 1, 2, 3,
4, 5, 6, 7, 8, 9.
:::

:::{.callout-note}
## What do we mean by *random*?

We have been throwing around the term random, but now we will say a little
more about what we mean by it.

We say something is random when we cannot completely predict the result.  The randomness is the part we cannot predict.

Let us say we toss a coin, and we could get either a *head* or a *tail*.  Let
us also say that we know for sure that 50% of time we get a head and 50% we
get a tail.  We can predict some things about this coin toss.  We can predict
that it will either be a head or a tail, and we can predict that it will be a
head 50% of the time. But we can't predict which of heads or tails we will get
on the next throw.  We say the result of each throw is *random* if we cannot
do anything to improve our prediction of 50% for heads (or tails) on the next
toss.
:::

When we ask for a random counting number from zero

This is how to get 17 random numbers 

::: python
We will be asking the computer to generate many random numbers.  So, before we
start, we again import NumPy and get its *random number generator*:

```{python, opts.label="py_ed"}
import numpy as np

# Ask for NumPy's default random number generator and name
# it `rnd`.  `rnd` is short for "random".
rnd = np.random.default_rng()
```
:::






```{python, opts.label="py_ed"}
outcomes = ['cured', 'cured', 'cured',
            'cured', 'cured', 'cured',
            'cured', 'cured', 'cured',
            'not cured']
single_patient_outcome = rnd.choice(outcomes)
```

Here, we take all possible outcomes and then ask NumPy to pick one at
random.  An equivalent, and more concise, alternative is to ask for
specific outcomes with given probabilities:

```python
single_patient_outcome = choice(['cured', 'not cured'], p=[0.9, 0.1])
```

:::{.callout-note}
## Array data types

Since we will be working with NumPy arrays a lot, it is worth knowing more about them.

A NumPy array is a container that stores many elements of the same type.  With type, we mean things like integers (-2, -1, 0, 1, 2, 3, etc.), floating point numbers (1.5, 3.3, etc.), objects like strings ("hello", "world", etc.), and boolean values (True or False).

Often, we will create a NumPy array to store our results before we begin.  We do this with the "zeros" command, which makes an empty array of a given size:

```{python}
x = np.zeros(3, dtype=int)
y = np.zeros(3, dtype=float)
z = np.zeros(3, dtype=bool)
print(x, y, z)
```

We can now assign elements into specific positions:

```{python}
x[2] = 5
print(x)
```

We will also be making use of arrays that store strings.  We initialize these arrays as above:

```{python}
w = np.zeros(3, dtype=object)
print(w)
```

Note that, by default, NumPy fills these arrays with zeros (integers).  But because the array is set to store *objects*, we can replace those integers with strings:

```{python}
w[1] = "hello"
w[2] = "world"
print(w)
```

What happens when we ask NumPy to check whether each element in the array is equal to "world"?  We get the following:

```{python}
w == "world"
```

This is a *boolean* array (True or False), telling us the answer to that question.  We often count the number of "True" responses as follows:

```{python}
np.count_nonzero(w == "world")
```

(In Python, True is equivalent to 1 and False is equivalent to 0.)
:::

Let us now simulate a single trial, where seventeen patients are treated
with the 90% effective treatment:

```{python}
N = 17

# An array of 17 slots in which we stored 'cured' or 'not cured' for
# each patient
cured = np.zeros(N, dtype=object)

for i in range(N):
    # For each of the 17 patients, do the following:

    outcome = rnd.choice(['cured', 'not cured'], p=[0.9, 0.1])

    # Store in the cured array at position i whether this patient
    # was cured or not
    cured[i] = 'cured'

# Count the number of patients cured
number_cured = np.count_nonzero(cured == 'cured')

# Were all 17 patients cured?  This will be True or False
all_cured = (number_cured == N)
```

:::{.callout-note}
## For-loops in Python

We first saw for-loops in Chapter @sec-resampling-method.  We will now dive
into them a bit more deeply.

Imagine a factory robot that slides along a worktable on which several
items have been placed.  It services each of these items, one by one,
until it is done.

So the robot knows *which* item it is operating on, each item is given
a label.

Here is an example:

```{python}
for item in ['shoe', 'saddle', 'jacket']:
    print('I am stitching a', item)
```

Here, the robot is working its way through three items: a shoe, a saddle, and a jacket.
As it moves on to each object, it assigns the label ("shoe", "saddle", etc.) to the variable `item`.
The indented block of code under the for is executed for each item, and in this code block `label` can be accessed.
The code above can therefore be unpacked into the following equivalent program:

```python
item = 'shoe'
print('I am stitching a', item)

item = 'saddle'
print('I am stitching a', item)

item = 'jacket'
print('I am stitching a', item)
```

We used the name `item` here, but any other name would do.
Thus, the following is equivalent:

```python
for package in ['shoe', 'saddle', 'jacket']:
    print('I am stitching a', package)
```

It is common to use a number as a label in a for loop:

```{python}
for i in [0, 1, 2, 3, 4]:
    print('The square of', i, 'is', i * i)
```

When we want to count to a hundred, it becomes laborious to type out the numbers.
For that, Python has a shorthand called `range`:

```{python}
for i in range(5):
    print('The square of', i, ' is ', i * i)
```
:::

Here, for each of the 17 patients, we draw 'cured' (90% probable) or 'not cured' (10% probable) from our outcomes.
We could just as easily draw all 17 outcomes at the same time:

```{python}
cured = rnd.choice(['cured', 'not cured'], p=[0.9, 0.1], size=17)
number_cured = np.count_nonzero(cured == 'cured')
all_cured = (number_cured == N)
```

Instead of explicitly counting the number of cured patients, we can also use the NumPy `all` command:

```{python}
cured = rnd.choice(['cured', 'not cured'], p=[0.9, 0.1], size=17)

# This is True or False
all_cured = np.all(cured == 'cured')
```

The above resembles one trial where 17 patients were treated.  We would like to count, over many trials, how often *all* patients were cured:

```{python}
T = 10000

# Array to store trial outcomes in
z = np.zeros(T, dtype=bool)

for i in range(T):
    cured = rnd.choice(['cured', 'not cured'], p=[0.9, 0.1], size=17)
    all_cured = np.all(cured == 'cured')

    z[i] = all_cured

# Determine in how many trials all patients were cured
k = np.count_nonzero(z)

# Convert to a proportion
kk = k / T

print(kk)
```

From this experiment, we see that there is roughly a one-in-six chance that all 17 patients are cured when using a 90% effective treatment.

---

Here is our first
{{< var lang >}}
example program.  Do not expect to
follow all of it straightaway.  For now, read the code below to get an
idea of how it implements the procedure above.  We will be coming back
to the specifics later.

The key to reading code is to think about what the computer will do, when it sees the code.


::: {.notebook name="resampling_with_code"}

A simple place to start is the *comment*.  A comment is a statement that the
computer will *ignore*.   It is text that we put in the program for our
benefit, to explain what is going on to a human reader.

This is an example of a comment:

```{python, opts.label="py_ed"}
# This is a comment. It doesn't have any effect.
```

```{r, opts.label="r_ed"}
# This is a comment. It doesn't have any effect.
```

The comment starts with a hash character `#`.  This character tells the
computer that the rest of the line is a comment, and therefore, that it can
ignore everything on that line that follows the `#`.

::: python

In the next bit of code, we load the *function* `randint` that
produces random numbers.

The code has four lines.  The first and third are comments; the
computer ignores them. The second line loads the NumPy library that we
use in nearly all our examples, and the last line loads the function
to generate random numbers.  After we run this code, we have a
function called `randint`, and a library called `np`.

```{python, opts.label="py_ed"}
# Import the numpy library
import numpy as np
# Get the function to generate random numbers.
from numpy.random import randint
```

:::

To solve the problem, we have to generate some random numbers:

::: python

```{python, opts.label="py_ed"}
a = randint(1, 11, 20)
```

This uses the `randint` *function* to generate random integers (counting numbers) from 1 up to, *but not including*, 11.  Therefore, this command will generate random numbers from 1 through 10.  The 20 in the command tells the function to generate 20 of these numbers.

:::

::: r

```{r, opts.label="r_ed"}
a = sample(1:10, 20, replace=TRUE)
```

This uses the `sample` function to generate random integers (counting numbers)
from 1 through 10.  The 20 in the command tells R to generate 20 of these
numbers.  `replace=TRUE` tells R to sample *with replacement*.

For example, the chances of getting a particular result - such as a 3 - for the
first random number - are 1 in 10, or p= 1/10 = 0.1.  If we resample *with
replacement* then the chances of getting 3 in the second number are unchanged,
at p=0.1.  It is as if we put 10 balls into a bucket, numbered one through ten,
and then selected 20 balls from the bucket; but after we have selected a ball,
we record the number and *replace* it in the bucket, and shake up the bucket
again.

:::

Inasmuch as each ambulance has a 1 in 10 chance of being
defective, we decide arbitrarily that a "1" stands for a defective ambulance,
and the other nine numbers (from "2" to "10") stand for a not-defective
ambulance. The command above orders the computer to store the results of the random
drawing in a location in the computer's memory to which we give a name, in this case `a` (we could have chosen any name such as, for example, `ambulances`).  When we run a statement like the one above, `a` is
a *variable* - the *name* `a` refers to the *value*, which is the sequence of
random numbers the computer created using
[`randint`]{.python}[`sample`]{.r}

We can display the value of the variable `a` by using the `print` function:

```{python, opts.label="py_ed"}
print(a)
```

```{r, opts.label="r_ed"}
print(a)
```

This shows the 20 random values that we got from
[`randint`]{.python}[`sample`]{.r}


The next key element in the core of the program is:

```{python, opts.label="py_ed"}
b = np.count_nonzero(a == 1)
```

```{r, opts.label="r_ed"}
b = sum(a == 1)
```

This command can be broken up into two pieces: the first (`a == 1`)
compares each element in `a` to 1, resulting in a True or False
value. We then proceed to count those values, to determine how many of
the 20 values in `a` are equal to 1. The result of the count will be
somewhere between 0 and 20, the number of ambulances that might be
out-of-order on a given day. The result is then placed in another
location in the computer's memory that we label `b`.

```{python, opts.label="py_ed"}
# Show the value of b
print(b)
```

```{r, opts.label="r_ed"}
# Show the value of b
print(b)
```

Now let us place the commands to generate the random numbers, and count how
many `1`s we get, within a program that solves this problem:

```{python, opts.label="py_ed"}
# Make an array that has 400 elements.
# We will use this to store the counts for our 400 repetitions
results = np.zeros(400)

# Repeat the simulation 400 times
for i in np.arange(400):

    # The indented commands are the procedure for one trial.
    # The computer runs these commands from first to last, for each trial.

    # Generate 20 numbers, each between "1" and "10," and put them in vector a.
    # Each number will represent an ambulance, and we let 1 represent
    # a defective ambulance.
    a = randint(1, 11, 20)

    # Count the number of defective ambulances, and put the result in b.
    b = np.count_nonzero(a == 1)

    # Keep track of each trial's result in "results".
    results[i] = b

    # End this trial, then go back and repeat the process until all 400 trials
    # are complete.

# Now we have finished the 400 trials.

# Determine how many trials resulted in more than 3 ambulances out of order.
bad_day_count = np.count_nonzero(results > 3)

# Convert to a proportion.
bad_day_prop = bad_day_count / 400

# Print the result.
print(bad_day_prop)
```

```{r, opts.label="r_ed"}
# Make an array that has 400 elements.
# We will use this to store the counts for our 400 repetitions
results <- numeric(400)

# Repeat the simulation 400 times
for (i in 1:400) {

    # The commands between the { above and the } below are the procedure for
    # one trial.
    # The computer runs these commands from first to last, for each trial.

    # Generate 20 numbers, each between "1" and "10," and put them in vector a.
    # Each number will represent an ambulance, and we let 1 represent
    # a defective ambulance.
    a <- sample(1:10, 20, replace=TRUE)

    # Count the number of defective ambulances, and put the result in b.
    b <- sum(a == 1)

    # Keep track of each trial's result in "results".
    results[i] <- b

    # End this trial, then go back and repeat the process until all 400 trials
    # are complete.
}

# Now we have finished the 400 trials.

# Determine how many trials resulted in more than 3 ambulances out of order.
bad_day_count <- sum(results > 3)

# Convert to a proportion.
bad_day_prop <- bad_day_count / 400

# Print the result.
print(bad_day_prop)
```

:::

The
[`results[i] = b`]{.python}[`results[i] <- b`]{.r}
statement that follows the
[`b = np.count_nonzero(a == 1)`]{.python}[`b = sum(a == 1)`]{.r}
operation keeps track of the results of each trial, placing the number
of defective ambulances that occur in each trial in a location that we
call "results". This is done in each of the 400 trials that we make, and the
result eventually is a "vector" with 400 numbers in it.  A vector is just
a sequence of numbers.

In order to make 400 repetitions of our experiment --- we could have
decided to make a thousand or some other number of repetitions --- we put
[`for i in np.arange(400):`]{.python}[`for (i in 1:400) {`]{.r}
before the statements that generate the random numbers, count how many of these numbers are 1, representing a defective ambulance, and store this result
of a single trial. Then we complete each repetition "loop" by
[bringing the indentation of the statements back to the left margin]{.python}
[adding a closing `}` bracket]{.r}.

Since our aim is to count the number of days in which more than 3 (4 or more)
defective ambulances occur, we use the
[`bad_day_count = np.count_nonzero(results > 3)`]{.python}
[`bad_day_count = sum(results > 3)`]{.r}
command to count how many times in the 400 days recorded in our results vector
at the end of the 400 trials more than 3 defects occurred, and we place the
result in still another location: `bad_day_count`.

This gives us the total number of days where 4 or more defective ambulances are
seen to occur. Then we divide the number in "bad_day_count" by 400, the number
of trials. Thus we obtain an estimate of the chance, expressed as a probability
between 0 and 1, that 4 or more ambulances will be defective on a given day.
And we store that result in a location that we decide to call `bad_day_prop` so
that it will be there when the computer receives the next command to `print`
that result on the screen.

Can you see how each of the operations that the computer carries out are
analogous to the operations that you yourself executed when you solved this
problem using a labeled coins or a random-number table? This is exactly the
procedure that we will use to solve every problem in probability and statistics
that we must deal with. Either we will use a device such as coins or a random
number table as an analogy for the physical process we are interested in
(ambulances becoming defective, in this case), or we will simulate the analogy
on the computer using the {{< var lang >}} program above.

The program above may not seem simple at first glance, but we think
you will find, over the course of this book, that these programs
become much simpler to understand than the older conventional approach
to such problems that has routinely been taught to students for
decades.
